{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def read_imdb_split(split_dir):\n",
    "    split_dir = Path(split_dir)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label_dir in [\"pos\", \"neg\"]:\n",
    "        for text_file in (split_dir/label_dir).iterdir():\n",
    "            texts.append(text_file.read_text(encoding=\"utf-8\"))\n",
    "            labels.append(0 if label_dir is \"neg\" else 1)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
    "test_texts, test_labels = read_imdb_split('aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 05:05:40.411082  6692 filelock.py:274] Lock 1908298639816 acquired on C:\\Users\\User/.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d869c2944dab4068a0dd02ece835ef8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 05:05:41.280439  6692 filelock.py:318] Lock 1908298639816 released on C:\\Users\\User/.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 05:05:41.824819  6692 filelock.py:274] Lock 1908299549000 acquired on C:\\Users\\User/.cache\\torch\\transformers\\ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38724f9d7ffb48ea8132ebdfe337f1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 05:05:48.716256  6692 filelock.py:318] Lock 1908299549000 released on C:\\Users\\User/.cache\\torch\\transformers\\ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780a692643d4b6aabc8a1c8ab225bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d962d53119d94d72b6e06e3e1b317067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6864083290100098, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.008, 'step': 10}\n",
      "{'loss': 0.694526195526123, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.016, 'step': 20}\n",
      "{'loss': 0.6883115768432617, 'learning_rate': 3e-06, 'epoch': 0.024, 'step': 30}\n",
      "{'loss': 0.6869350433349609, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.032, 'step': 40}\n",
      "{'loss': 0.6809392929077148, 'learning_rate': 5e-06, 'epoch': 0.04, 'step': 50}\n",
      "{'loss': 0.6674755096435547, 'learning_rate': 6e-06, 'epoch': 0.048, 'step': 60}\n",
      "{'loss': 0.6616851806640625, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.056, 'step': 70}\n",
      "{'loss': 0.6221721649169922, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.064, 'step': 80}\n",
      "{'loss': 0.5116352081298828, 'learning_rate': 9e-06, 'epoch': 0.072, 'step': 90}\n",
      "{'loss': 0.45932960510253906, 'learning_rate': 1e-05, 'epoch': 0.08, 'step': 100}\n",
      "{'loss': 0.3264110565185547, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.088, 'step': 110}\n",
      "{'loss': 0.35470428466796877, 'learning_rate': 1.2e-05, 'epoch': 0.096, 'step': 120}\n",
      "{'loss': 0.3127876281738281, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.104, 'step': 130}\n",
      "{'loss': 0.32319793701171873, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.112, 'step': 140}\n",
      "{'loss': 0.345758056640625, 'learning_rate': 1.5e-05, 'epoch': 0.12, 'step': 150}\n",
      "{'loss': 0.2626953125, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.128, 'step': 160}\n",
      "{'loss': 0.28462066650390627, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.136, 'step': 170}\n",
      "{'loss': 0.33275527954101564, 'learning_rate': 1.8e-05, 'epoch': 0.144, 'step': 180}\n",
      "{'loss': 0.5283821105957032, 'learning_rate': 1.9e-05, 'epoch': 0.152, 'step': 190}\n",
      "{'loss': 0.27214889526367186, 'learning_rate': 2e-05, 'epoch': 0.16, 'step': 200}\n",
      "{'loss': 0.3065650939941406, 'learning_rate': 2.1e-05, 'epoch': 0.168, 'step': 210}\n",
      "{'loss': 0.35740814208984373, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.176, 'step': 220}\n",
      "{'loss': 0.3450019836425781, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.184, 'step': 230}\n",
      "{'loss': 0.3386749267578125, 'learning_rate': 2.4e-05, 'epoch': 0.192, 'step': 240}\n",
      "{'loss': 0.24415740966796876, 'learning_rate': 2.5e-05, 'epoch': 0.2, 'step': 250}\n",
      "{'loss': 0.35415115356445315, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.208, 'step': 260}\n",
      "{'loss': 0.42712860107421874, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.216, 'step': 270}\n",
      "{'loss': 0.3753204345703125, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.224, 'step': 280}\n",
      "{'loss': 0.244378662109375, 'learning_rate': 2.9e-05, 'epoch': 0.232, 'step': 290}\n",
      "{'loss': 0.31302413940429685, 'learning_rate': 3e-05, 'epoch': 0.24, 'step': 300}\n",
      "{'loss': 0.26334991455078127, 'learning_rate': 3.1e-05, 'epoch': 0.248, 'step': 310}\n",
      "{'loss': 0.30535430908203126, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.256, 'step': 320}\n",
      "{'loss': 0.30728607177734374, 'learning_rate': 3.3e-05, 'epoch': 0.264, 'step': 330}\n",
      "{'loss': 0.18599395751953124, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.272, 'step': 340}\n",
      "{'loss': 0.36133270263671874, 'learning_rate': 3.5e-05, 'epoch': 0.28, 'step': 350}\n",
      "{'loss': 0.2241485595703125, 'learning_rate': 3.6e-05, 'epoch': 0.288, 'step': 360}\n",
      "{'loss': 0.3029205322265625, 'learning_rate': 3.7e-05, 'epoch': 0.296, 'step': 370}\n",
      "{'loss': 0.2839385986328125, 'learning_rate': 3.8e-05, 'epoch': 0.304, 'step': 380}\n",
      "{'loss': 0.34421539306640625, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.312, 'step': 390}\n",
      "{'loss': 0.32010650634765625, 'learning_rate': 4e-05, 'epoch': 0.32, 'step': 400}\n",
      "{'loss': 0.25756988525390623, 'learning_rate': 4.1e-05, 'epoch': 0.328, 'step': 410}\n",
      "{'loss': 0.36625823974609373, 'learning_rate': 4.2e-05, 'epoch': 0.336, 'step': 420}\n",
      "{'loss': 0.3554656982421875, 'learning_rate': 4.3e-05, 'epoch': 0.344, 'step': 430}\n",
      "{'loss': 0.35938873291015627, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.352, 'step': 440}\n",
      "{'loss': 0.43926239013671875, 'learning_rate': 4.5e-05, 'epoch': 0.36, 'step': 450}\n",
      "{'loss': 0.314404296875, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.368, 'step': 460}\n",
      "{'loss': 0.29242706298828125, 'learning_rate': 4.7e-05, 'epoch': 0.376, 'step': 470}\n",
      "{'loss': 0.23026580810546876, 'learning_rate': 4.8e-05, 'epoch': 0.384, 'step': 480}\n",
      "{'loss': 0.31100921630859374, 'learning_rate': 4.9e-05, 'epoch': 0.392, 'step': 490}\n",
      "{'loss': 0.3668243408203125, 'learning_rate': 5e-05, 'epoch': 0.4, 'step': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2766021728515625, 'learning_rate': 4.984615384615385e-05, 'epoch': 0.408, 'step': 510}\n",
      "{'loss': 0.426080322265625, 'learning_rate': 4.969230769230769e-05, 'epoch': 0.416, 'step': 520}\n",
      "{'loss': 0.415313720703125, 'learning_rate': 4.953846153846154e-05, 'epoch': 0.424, 'step': 530}\n",
      "{'loss': 0.337548828125, 'learning_rate': 4.9384615384615384e-05, 'epoch': 0.432, 'step': 540}\n",
      "{'loss': 0.2964202880859375, 'learning_rate': 4.923076923076924e-05, 'epoch': 0.44, 'step': 550}\n",
      "{'loss': 0.347186279296875, 'learning_rate': 4.907692307692308e-05, 'epoch': 0.448, 'step': 560}\n",
      "{'loss': 0.259088134765625, 'learning_rate': 4.892307692307693e-05, 'epoch': 0.456, 'step': 570}\n",
      "{'loss': 0.27161712646484376, 'learning_rate': 4.876923076923077e-05, 'epoch': 0.464, 'step': 580}\n",
      "{'loss': 0.38050384521484376, 'learning_rate': 4.861538461538462e-05, 'epoch': 0.472, 'step': 590}\n",
      "{'loss': 0.30739288330078124, 'learning_rate': 4.846153846153846e-05, 'epoch': 0.48, 'step': 600}\n",
      "{'loss': 0.29326019287109373, 'learning_rate': 4.830769230769231e-05, 'epoch': 0.488, 'step': 610}\n",
      "{'loss': 0.4141265869140625, 'learning_rate': 4.815384615384615e-05, 'epoch': 0.496, 'step': 620}\n",
      "{'loss': 0.2356475830078125, 'learning_rate': 4.8e-05, 'epoch': 0.504, 'step': 630}\n",
      "{'loss': 0.42168731689453126, 'learning_rate': 4.784615384615384e-05, 'epoch': 0.512, 'step': 640}\n",
      "{'loss': 0.24944305419921875, 'learning_rate': 4.76923076923077e-05, 'epoch': 0.52, 'step': 650}\n",
      "{'loss': 0.329425048828125, 'learning_rate': 4.753846153846154e-05, 'epoch': 0.528, 'step': 660}\n",
      "{'loss': 0.197650146484375, 'learning_rate': 4.738461538461539e-05, 'epoch': 0.536, 'step': 670}\n",
      "{'loss': 0.42705230712890624, 'learning_rate': 4.723076923076923e-05, 'epoch': 0.544, 'step': 680}\n",
      "{'loss': 0.29381561279296875, 'learning_rate': 4.707692307692308e-05, 'epoch': 0.552, 'step': 690}\n",
      "{'loss': 0.28782501220703127, 'learning_rate': 4.692307692307693e-05, 'epoch': 0.56, 'step': 700}\n",
      "{'loss': 0.2222259521484375, 'learning_rate': 4.676923076923077e-05, 'epoch': 0.568, 'step': 710}\n",
      "{'loss': 0.3105560302734375, 'learning_rate': 4.661538461538462e-05, 'epoch': 0.576, 'step': 720}\n",
      "{'loss': 0.2638671875, 'learning_rate': 4.646153846153846e-05, 'epoch': 0.584, 'step': 730}\n",
      "{'loss': 0.19437255859375, 'learning_rate': 4.630769230769231e-05, 'epoch': 0.592, 'step': 740}\n",
      "{'loss': 0.1827392578125, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.6, 'step': 750}\n",
      "{'loss': 0.3063079833984375, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.608, 'step': 760}\n",
      "{'loss': 0.2495849609375, 'learning_rate': 4.584615384615385e-05, 'epoch': 0.616, 'step': 770}\n",
      "{'loss': 0.2814666748046875, 'learning_rate': 4.56923076923077e-05, 'epoch': 0.624, 'step': 780}\n",
      "{'loss': 0.2226806640625, 'learning_rate': 4.553846153846154e-05, 'epoch': 0.632, 'step': 790}\n",
      "{'loss': 0.1875885009765625, 'learning_rate': 4.538461538461539e-05, 'epoch': 0.64, 'step': 800}\n",
      "{'loss': 0.2800323486328125, 'learning_rate': 4.523076923076923e-05, 'epoch': 0.648, 'step': 810}\n",
      "{'loss': 0.2558990478515625, 'learning_rate': 4.507692307692308e-05, 'epoch': 0.656, 'step': 820}\n",
      "{'loss': 0.2498748779296875, 'learning_rate': 4.492307692307692e-05, 'epoch': 0.664, 'step': 830}\n",
      "{'loss': 0.2365966796875, 'learning_rate': 4.476923076923077e-05, 'epoch': 0.672, 'step': 840}\n",
      "{'loss': 0.2656280517578125, 'learning_rate': 4.461538461538462e-05, 'epoch': 0.68, 'step': 850}\n",
      "{'loss': 0.2112640380859375, 'learning_rate': 4.4461538461538466e-05, 'epoch': 0.688, 'step': 860}\n",
      "{'loss': 0.23643798828125, 'learning_rate': 4.430769230769231e-05, 'epoch': 0.696, 'step': 870}\n",
      "{'loss': 0.26376953125, 'learning_rate': 4.415384615384616e-05, 'epoch': 0.704, 'step': 880}\n",
      "{'loss': 0.255364990234375, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.712, 'step': 890}\n",
      "{'loss': 0.1864105224609375, 'learning_rate': 4.384615384615385e-05, 'epoch': 0.72, 'step': 900}\n",
      "{'loss': 0.2292633056640625, 'learning_rate': 4.3692307692307696e-05, 'epoch': 0.728, 'step': 910}\n",
      "{'loss': 0.1807464599609375, 'learning_rate': 4.353846153846154e-05, 'epoch': 0.736, 'step': 920}\n",
      "{'loss': 0.2335723876953125, 'learning_rate': 4.338461538461539e-05, 'epoch': 0.744, 'step': 930}\n",
      "{'loss': 0.2265167236328125, 'learning_rate': 4.323076923076923e-05, 'epoch': 0.752, 'step': 940}\n",
      "{'loss': 0.279815673828125, 'learning_rate': 4.3076923076923084e-05, 'epoch': 0.76, 'step': 950}\n",
      "{'loss': 0.3683013916015625, 'learning_rate': 4.2923076923076926e-05, 'epoch': 0.768, 'step': 960}\n",
      "{'loss': 0.226751708984375, 'learning_rate': 4.2769230769230775e-05, 'epoch': 0.776, 'step': 970}\n",
      "{'loss': 0.339178466796875, 'learning_rate': 4.2615384615384617e-05, 'epoch': 0.784, 'step': 980}\n",
      "{'loss': 0.25533447265625, 'learning_rate': 4.2461538461538465e-05, 'epoch': 0.792, 'step': 990}\n",
      "{'loss': 0.3121368408203125, 'learning_rate': 4.230769230769231e-05, 'epoch': 0.8, 'step': 1000}\n",
      "{'loss': 0.211981201171875, 'learning_rate': 4.2153846153846156e-05, 'epoch': 0.808, 'step': 1010}\n",
      "{'loss': 0.371893310546875, 'learning_rate': 4.2e-05, 'epoch': 0.816, 'step': 1020}\n",
      "{'loss': 0.24351806640625, 'learning_rate': 4.1846153846153846e-05, 'epoch': 0.824, 'step': 1030}\n",
      "{'loss': 0.19129638671875, 'learning_rate': 4.169230769230769e-05, 'epoch': 0.832, 'step': 1040}\n",
      "{'loss': 0.2419708251953125, 'learning_rate': 4.1538461538461544e-05, 'epoch': 0.84, 'step': 1050}\n",
      "{'loss': 0.173370361328125, 'learning_rate': 4.1384615384615386e-05, 'epoch': 0.848, 'step': 1060}\n",
      "{'loss': 0.3811309814453125, 'learning_rate': 4.1230769230769234e-05, 'epoch': 0.856, 'step': 1070}\n",
      "{'loss': 0.233648681640625, 'learning_rate': 4.1076923076923076e-05, 'epoch': 0.864, 'step': 1080}\n",
      "{'loss': 0.2330963134765625, 'learning_rate': 4.0923076923076925e-05, 'epoch': 0.872, 'step': 1090}\n",
      "{'loss': 0.2693511962890625, 'learning_rate': 4.0769230769230773e-05, 'epoch': 0.88, 'step': 1100}\n",
      "{'loss': 0.282586669921875, 'learning_rate': 4.0615384615384615e-05, 'epoch': 0.888, 'step': 1110}\n",
      "{'loss': 0.2526885986328125, 'learning_rate': 4.0461538461538464e-05, 'epoch': 0.896, 'step': 1120}\n",
      "{'loss': 0.22939453125, 'learning_rate': 4.0307692307692306e-05, 'epoch': 0.904, 'step': 1130}\n",
      "{'loss': 0.2058349609375, 'learning_rate': 4.0153846153846155e-05, 'epoch': 0.912, 'step': 1140}\n",
      "{'loss': 0.225030517578125, 'learning_rate': 4e-05, 'epoch': 0.92, 'step': 1150}\n",
      "{'loss': 0.2988311767578125, 'learning_rate': 3.984615384615385e-05, 'epoch': 0.928, 'step': 1160}\n",
      "{'loss': 0.2739593505859375, 'learning_rate': 3.9692307692307694e-05, 'epoch': 0.936, 'step': 1170}\n",
      "{'loss': 0.223406982421875, 'learning_rate': 3.953846153846154e-05, 'epoch': 0.944, 'step': 1180}\n",
      "{'loss': 0.298345947265625, 'learning_rate': 3.9384615384615384e-05, 'epoch': 0.952, 'step': 1190}\n",
      "{'loss': 0.438641357421875, 'learning_rate': 3.923076923076923e-05, 'epoch': 0.96, 'step': 1200}\n",
      "{'loss': 0.267205810546875, 'learning_rate': 3.9076923076923075e-05, 'epoch': 0.968, 'step': 1210}\n",
      "{'loss': 0.2409515380859375, 'learning_rate': 3.8923076923076924e-05, 'epoch': 0.976, 'step': 1220}\n",
      "{'loss': 0.20562744140625, 'learning_rate': 3.8769230769230766e-05, 'epoch': 0.984, 'step': 1230}\n",
      "{'loss': 0.1747955322265625, 'learning_rate': 3.861538461538462e-05, 'epoch': 0.992, 'step': 1240}\n",
      "{'loss': 0.2546295166015625, 'learning_rate': 3.846153846153846e-05, 'epoch': 1.0, 'step': 1250}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d376418c56da49fe8d41029d821d7856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2479034423828125, 'learning_rate': 3.830769230769231e-05, 'epoch': 1.008, 'step': 1260}\n",
      "{'loss': 0.1425445556640625, 'learning_rate': 3.8153846153846153e-05, 'epoch': 1.016, 'step': 1270}\n",
      "{'loss': 0.09515380859375, 'learning_rate': 3.8e-05, 'epoch': 1.024, 'step': 1280}\n",
      "{'loss': 0.2122589111328125, 'learning_rate': 3.784615384615385e-05, 'epoch': 1.032, 'step': 1290}\n",
      "{'loss': 0.1574859619140625, 'learning_rate': 3.769230769230769e-05, 'epoch': 1.04, 'step': 1300}\n",
      "{'loss': 0.1630462646484375, 'learning_rate': 3.753846153846154e-05, 'epoch': 1.048, 'step': 1310}\n",
      "{'loss': 0.06728515625, 'learning_rate': 3.738461538461538e-05, 'epoch': 1.056, 'step': 1320}\n",
      "{'loss': 0.155352783203125, 'learning_rate': 3.723076923076923e-05, 'epoch': 1.064, 'step': 1330}\n",
      "{'loss': 0.241119384765625, 'learning_rate': 3.707692307692308e-05, 'epoch': 1.072, 'step': 1340}\n",
      "{'loss': 0.1820404052734375, 'learning_rate': 3.692307692307693e-05, 'epoch': 1.08, 'step': 1350}\n",
      "{'loss': 0.1498992919921875, 'learning_rate': 3.676923076923077e-05, 'epoch': 1.088, 'step': 1360}\n",
      "{'loss': 0.152410888671875, 'learning_rate': 3.661538461538462e-05, 'epoch': 1.096, 'step': 1370}\n",
      "{'loss': 0.2731903076171875, 'learning_rate': 3.646153846153846e-05, 'epoch': 1.104, 'step': 1380}\n",
      "{'loss': 0.157666015625, 'learning_rate': 3.630769230769231e-05, 'epoch': 1.112, 'step': 1390}\n",
      "{'loss': 0.1895233154296875, 'learning_rate': 3.615384615384615e-05, 'epoch': 1.12, 'step': 1400}\n",
      "{'loss': 0.1409271240234375, 'learning_rate': 3.6e-05, 'epoch': 1.1280000000000001, 'step': 1410}\n",
      "{'loss': 0.107830810546875, 'learning_rate': 3.584615384615384e-05, 'epoch': 1.1360000000000001, 'step': 1420}\n",
      "{'loss': 0.2588714599609375, 'learning_rate': 3.569230769230769e-05, 'epoch': 1.144, 'step': 1430}\n",
      "{'loss': 0.196820068359375, 'learning_rate': 3.553846153846154e-05, 'epoch': 1.152, 'step': 1440}\n",
      "{'loss': 0.2893585205078125, 'learning_rate': 3.538461538461539e-05, 'epoch': 1.16, 'step': 1450}\n",
      "{'loss': 0.0617950439453125, 'learning_rate': 3.523076923076923e-05, 'epoch': 1.168, 'step': 1460}\n",
      "{'loss': 0.2542083740234375, 'learning_rate': 3.507692307692308e-05, 'epoch': 1.176, 'step': 1470}\n",
      "{'loss': 0.1348358154296875, 'learning_rate': 3.492307692307693e-05, 'epoch': 1.184, 'step': 1480}\n",
      "{'loss': 0.1549285888671875, 'learning_rate': 3.476923076923077e-05, 'epoch': 1.192, 'step': 1490}\n",
      "{'loss': 0.05191650390625, 'learning_rate': 3.461538461538462e-05, 'epoch': 1.2, 'step': 1500}\n",
      "{'loss': 0.0974517822265625, 'learning_rate': 3.446153846153846e-05, 'epoch': 1.208, 'step': 1510}\n",
      "{'loss': 0.1533538818359375, 'learning_rate': 3.430769230769231e-05, 'epoch': 1.216, 'step': 1520}\n",
      "{'loss': 0.22691650390625, 'learning_rate': 3.415384615384615e-05, 'epoch': 1.224, 'step': 1530}\n",
      "{'loss': 0.1242767333984375, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.232, 'step': 1540}\n",
      "{'loss': 0.1405975341796875, 'learning_rate': 3.384615384615385e-05, 'epoch': 1.24, 'step': 1550}\n",
      "{'loss': 0.1429046630859375, 'learning_rate': 3.36923076923077e-05, 'epoch': 1.248, 'step': 1560}\n",
      "{'loss': 0.130377197265625, 'learning_rate': 3.353846153846154e-05, 'epoch': 1.256, 'step': 1570}\n",
      "{'loss': 0.133917236328125, 'learning_rate': 3.338461538461539e-05, 'epoch': 1.264, 'step': 1580}\n",
      "{'loss': 0.1608917236328125, 'learning_rate': 3.323076923076923e-05, 'epoch': 1.272, 'step': 1590}\n",
      "{'loss': 0.1668487548828125, 'learning_rate': 3.307692307692308e-05, 'epoch': 1.28, 'step': 1600}\n",
      "{'loss': 0.1624664306640625, 'learning_rate': 3.292307692307692e-05, 'epoch': 1.288, 'step': 1610}\n",
      "{'loss': 0.1310943603515625, 'learning_rate': 3.276923076923077e-05, 'epoch': 1.296, 'step': 1620}\n",
      "{'loss': 0.26260986328125, 'learning_rate': 3.261538461538462e-05, 'epoch': 1.304, 'step': 1630}\n",
      "{'loss': 0.1678680419921875, 'learning_rate': 3.2461538461538466e-05, 'epoch': 1.312, 'step': 1640}\n",
      "{'loss': 0.1946014404296875, 'learning_rate': 3.230769230769231e-05, 'epoch': 1.32, 'step': 1650}\n",
      "{'loss': 0.13927001953125, 'learning_rate': 3.215384615384616e-05, 'epoch': 1.328, 'step': 1660}\n",
      "{'loss': 0.09544677734375, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.336, 'step': 1670}\n",
      "{'loss': 0.2116790771484375, 'learning_rate': 3.184615384615385e-05, 'epoch': 1.3439999999999999, 'step': 1680}\n",
      "{'loss': 0.1478515625, 'learning_rate': 3.1692307692307696e-05, 'epoch': 1.3519999999999999, 'step': 1690}\n",
      "{'loss': 0.186517333984375, 'learning_rate': 3.153846153846154e-05, 'epoch': 1.3599999999999999, 'step': 1700}\n",
      "{'loss': 0.155621337890625, 'learning_rate': 3.1384615384615386e-05, 'epoch': 1.3679999999999999, 'step': 1710}\n",
      "{'loss': 0.1579681396484375, 'learning_rate': 3.123076923076923e-05, 'epoch': 1.376, 'step': 1720}\n",
      "{'loss': 0.19200439453125, 'learning_rate': 3.107692307692308e-05, 'epoch': 1.384, 'step': 1730}\n",
      "{'loss': 0.1014801025390625, 'learning_rate': 3.0923076923076926e-05, 'epoch': 1.392, 'step': 1740}\n",
      "{'loss': 0.22230224609375, 'learning_rate': 3.0769230769230774e-05, 'epoch': 1.4, 'step': 1750}\n",
      "{'loss': 0.2469696044921875, 'learning_rate': 3.0615384615384616e-05, 'epoch': 1.408, 'step': 1760}\n",
      "{'loss': 0.2330169677734375, 'learning_rate': 3.0461538461538465e-05, 'epoch': 1.416, 'step': 1770}\n",
      "{'loss': 0.170733642578125, 'learning_rate': 3.030769230769231e-05, 'epoch': 1.424, 'step': 1780}\n",
      "{'loss': 0.14630126953125, 'learning_rate': 3.0153846153846155e-05, 'epoch': 1.432, 'step': 1790}\n",
      "{'loss': 0.178521728515625, 'learning_rate': 3e-05, 'epoch': 1.44, 'step': 1800}\n",
      "{'loss': 0.102032470703125, 'learning_rate': 2.9846153846153846e-05, 'epoch': 1.448, 'step': 1810}\n",
      "{'loss': 0.1634124755859375, 'learning_rate': 2.969230769230769e-05, 'epoch': 1.456, 'step': 1820}\n",
      "{'loss': 0.1506195068359375, 'learning_rate': 2.9538461538461543e-05, 'epoch': 1.464, 'step': 1830}\n",
      "{'loss': 0.15859375, 'learning_rate': 2.938461538461539e-05, 'epoch': 1.472, 'step': 1840}\n",
      "{'loss': 0.236163330078125, 'learning_rate': 2.9230769230769234e-05, 'epoch': 1.48, 'step': 1850}\n",
      "{'loss': 0.1792205810546875, 'learning_rate': 2.907692307692308e-05, 'epoch': 1.488, 'step': 1860}\n",
      "{'loss': 0.202587890625, 'learning_rate': 2.8923076923076925e-05, 'epoch': 1.496, 'step': 1870}\n",
      "{'loss': 0.110150146484375, 'learning_rate': 2.876923076923077e-05, 'epoch': 1.504, 'step': 1880}\n",
      "{'loss': 0.1300018310546875, 'learning_rate': 2.8615384615384615e-05, 'epoch': 1.512, 'step': 1890}\n",
      "{'loss': 0.1949798583984375, 'learning_rate': 2.846153846153846e-05, 'epoch': 1.52, 'step': 1900}\n",
      "{'loss': 0.234185791015625, 'learning_rate': 2.8307692307692306e-05, 'epoch': 1.528, 'step': 1910}\n",
      "{'loss': 0.1552490234375, 'learning_rate': 2.8153846153846154e-05, 'epoch': 1.536, 'step': 1920}\n",
      "{'loss': 0.2070281982421875, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.544, 'step': 1930}\n",
      "{'loss': 0.20386962890625, 'learning_rate': 2.7846153846153848e-05, 'epoch': 1.552, 'step': 1940}\n",
      "{'loss': 0.161932373046875, 'learning_rate': 2.7692307692307694e-05, 'epoch': 1.56, 'step': 1950}\n",
      "{'loss': 0.140179443359375, 'learning_rate': 2.7538461538461542e-05, 'epoch': 1.568, 'step': 1960}\n",
      "{'loss': 0.227215576171875, 'learning_rate': 2.7384615384615387e-05, 'epoch': 1.576, 'step': 1970}\n",
      "{'loss': 0.1424560546875, 'learning_rate': 2.7230769230769233e-05, 'epoch': 1.584, 'step': 1980}\n",
      "{'loss': 0.1147705078125, 'learning_rate': 2.7076923076923078e-05, 'epoch': 1.592, 'step': 1990}\n",
      "{'loss': 0.12003173828125, 'learning_rate': 2.6923076923076923e-05, 'epoch': 1.6, 'step': 2000}\n",
      "{'loss': 0.10499267578125, 'learning_rate': 2.676923076923077e-05, 'epoch': 1.608, 'step': 2010}\n",
      "{'loss': 0.171173095703125, 'learning_rate': 2.6615384615384614e-05, 'epoch': 1.616, 'step': 2020}\n",
      "{'loss': 0.244708251953125, 'learning_rate': 2.6461538461538466e-05, 'epoch': 1.624, 'step': 2030}\n",
      "{'loss': 0.2046630859375, 'learning_rate': 2.630769230769231e-05, 'epoch': 1.6320000000000001, 'step': 2040}\n",
      "{'loss': 0.20633544921875, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.6400000000000001, 'step': 2050}\n",
      "{'loss': 0.108154296875, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.6480000000000001, 'step': 2060}\n",
      "{'loss': 0.158404541015625, 'learning_rate': 2.5846153846153847e-05, 'epoch': 1.6560000000000001, 'step': 2070}\n",
      "{'loss': 0.15147705078125, 'learning_rate': 2.5692307692307692e-05, 'epoch': 1.6640000000000001, 'step': 2080}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.290887451171875, 'learning_rate': 2.5538461538461538e-05, 'epoch': 1.6720000000000002, 'step': 2090}\n",
      "{'loss': 0.11649169921875, 'learning_rate': 2.5384615384615383e-05, 'epoch': 1.6800000000000002, 'step': 2100}\n",
      "{'loss': 0.198101806640625, 'learning_rate': 2.523076923076923e-05, 'epoch': 1.688, 'step': 2110}\n",
      "{'loss': 0.20836181640625, 'learning_rate': 2.5076923076923077e-05, 'epoch': 1.696, 'step': 2120}\n",
      "{'loss': 0.06085205078125, 'learning_rate': 2.4923076923076926e-05, 'epoch': 1.704, 'step': 2130}\n",
      "{'loss': 0.1255615234375, 'learning_rate': 2.476923076923077e-05, 'epoch': 1.712, 'step': 2140}\n",
      "{'loss': 0.16280517578125, 'learning_rate': 2.461538461538462e-05, 'epoch': 1.72, 'step': 2150}\n",
      "{'loss': 0.1289306640625, 'learning_rate': 2.4461538461538465e-05, 'epoch': 1.728, 'step': 2160}\n",
      "{'loss': 0.13631591796875, 'learning_rate': 2.430769230769231e-05, 'epoch': 1.736, 'step': 2170}\n",
      "{'loss': 0.206427001953125, 'learning_rate': 2.4153846153846155e-05, 'epoch': 1.744, 'step': 2180}\n",
      "{'loss': 0.21046142578125, 'learning_rate': 2.4e-05, 'epoch': 1.752, 'step': 2190}\n",
      "{'loss': 0.16104736328125, 'learning_rate': 2.384615384615385e-05, 'epoch': 1.76, 'step': 2200}\n",
      "{'loss': 0.2786865234375, 'learning_rate': 2.3692307692307695e-05, 'epoch': 1.768, 'step': 2210}\n",
      "{'loss': 0.165386962890625, 'learning_rate': 2.353846153846154e-05, 'epoch': 1.776, 'step': 2220}\n",
      "{'loss': 0.10023193359375, 'learning_rate': 2.3384615384615385e-05, 'epoch': 1.784, 'step': 2230}\n",
      "{'loss': 0.1338134765625, 'learning_rate': 2.323076923076923e-05, 'epoch': 1.792, 'step': 2240}\n",
      "{'loss': 0.139166259765625, 'learning_rate': 2.307692307692308e-05, 'epoch': 1.8, 'step': 2250}\n",
      "{'loss': 0.147515869140625, 'learning_rate': 2.2923076923076924e-05, 'epoch': 1.808, 'step': 2260}\n",
      "{'loss': 0.190289306640625, 'learning_rate': 2.276923076923077e-05, 'epoch': 1.8159999999999998, 'step': 2270}\n",
      "{'loss': 0.1134033203125, 'learning_rate': 2.2615384615384615e-05, 'epoch': 1.8239999999999998, 'step': 2280}\n",
      "{'loss': 0.098675537109375, 'learning_rate': 2.246153846153846e-05, 'epoch': 1.8319999999999999, 'step': 2290}\n",
      "{'loss': 0.216552734375, 'learning_rate': 2.230769230769231e-05, 'epoch': 1.8399999999999999, 'step': 2300}\n",
      "{'loss': 0.103216552734375, 'learning_rate': 2.2153846153846154e-05, 'epoch': 1.8479999999999999, 'step': 2310}\n",
      "{'loss': 0.133990478515625, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.8559999999999999, 'step': 2320}\n",
      "{'loss': 0.106597900390625, 'learning_rate': 2.1846153846153848e-05, 'epoch': 1.8639999999999999, 'step': 2330}\n",
      "{'loss': 0.10084228515625, 'learning_rate': 2.1692307692307693e-05, 'epoch': 1.8719999999999999, 'step': 2340}\n",
      "{'loss': 0.138232421875, 'learning_rate': 2.1538461538461542e-05, 'epoch': 1.88, 'step': 2350}\n",
      "{'loss': 0.220782470703125, 'learning_rate': 2.1384615384615387e-05, 'epoch': 1.888, 'step': 2360}\n",
      "{'loss': 0.1494140625, 'learning_rate': 2.1230769230769233e-05, 'epoch': 1.896, 'step': 2370}\n",
      "{'loss': 0.264544677734375, 'learning_rate': 2.1076923076923078e-05, 'epoch': 1.904, 'step': 2380}\n",
      "{'loss': 0.12581787109375, 'learning_rate': 2.0923076923076923e-05, 'epoch': 1.912, 'step': 2390}\n",
      "{'loss': 0.092266845703125, 'learning_rate': 2.0769230769230772e-05, 'epoch': 1.92, 'step': 2400}\n",
      "{'loss': 0.119036865234375, 'learning_rate': 2.0615384615384617e-05, 'epoch': 1.928, 'step': 2410}\n",
      "{'loss': 0.198919677734375, 'learning_rate': 2.0461538461538462e-05, 'epoch': 1.936, 'step': 2420}\n",
      "{'loss': 0.268426513671875, 'learning_rate': 2.0307692307692308e-05, 'epoch': 1.944, 'step': 2430}\n",
      "{'loss': 0.08909912109375, 'learning_rate': 2.0153846153846153e-05, 'epoch': 1.952, 'step': 2440}\n",
      "{'loss': 0.23184814453125, 'learning_rate': 2e-05, 'epoch': 1.96, 'step': 2450}\n",
      "{'loss': 0.067755126953125, 'learning_rate': 1.9846153846153847e-05, 'epoch': 1.968, 'step': 2460}\n",
      "{'loss': 0.195574951171875, 'learning_rate': 1.9692307692307692e-05, 'epoch': 1.976, 'step': 2470}\n",
      "{'loss': 0.14716796875, 'learning_rate': 1.9538461538461537e-05, 'epoch': 1.984, 'step': 2480}\n",
      "{'loss': 0.16226806640625, 'learning_rate': 1.9384615384615383e-05, 'epoch': 1.992, 'step': 2490}\n",
      "{'loss': 0.148382568359375, 'learning_rate': 1.923076923076923e-05, 'epoch': 2.0, 'step': 2500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c8899d7bc344269d1ef09120af34bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1250.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.03902587890625, 'learning_rate': 1.9076923076923077e-05, 'epoch': 2.008, 'step': 2510}\n",
      "{'loss': 0.057373046875, 'learning_rate': 1.8923076923076925e-05, 'epoch': 2.016, 'step': 2520}\n",
      "{'loss': 0.123223876953125, 'learning_rate': 1.876923076923077e-05, 'epoch': 2.024, 'step': 2530}\n",
      "{'loss': 0.041717529296875, 'learning_rate': 1.8615384615384616e-05, 'epoch': 2.032, 'step': 2540}\n",
      "{'loss': 0.1138916015625, 'learning_rate': 1.8461538461538465e-05, 'epoch': 2.04, 'step': 2550}\n",
      "{'loss': 0.02467041015625, 'learning_rate': 1.830769230769231e-05, 'epoch': 2.048, 'step': 2560}\n",
      "{'loss': 0.01309814453125, 'learning_rate': 1.8153846153846155e-05, 'epoch': 2.056, 'step': 2570}\n",
      "{'loss': 0.024267578125, 'learning_rate': 1.8e-05, 'epoch': 2.064, 'step': 2580}\n",
      "{'loss': 0.039697265625, 'learning_rate': 1.7846153846153846e-05, 'epoch': 2.072, 'step': 2590}\n",
      "{'loss': 0.01412353515625, 'learning_rate': 1.7692307692307694e-05, 'epoch': 2.08, 'step': 2600}\n",
      "{'loss': 0.099114990234375, 'learning_rate': 1.753846153846154e-05, 'epoch': 2.088, 'step': 2610}\n",
      "{'loss': 0.03885498046875, 'learning_rate': 1.7384615384615385e-05, 'epoch': 2.096, 'step': 2620}\n",
      "{'loss': 0.1162109375, 'learning_rate': 1.723076923076923e-05, 'epoch': 2.104, 'step': 2630}\n",
      "{'loss': 0.007525634765625, 'learning_rate': 1.7076923076923076e-05, 'epoch': 2.112, 'step': 2640}\n",
      "{'loss': 0.0172119140625, 'learning_rate': 1.6923076923076924e-05, 'epoch': 2.12, 'step': 2650}\n",
      "{'loss': 0.078271484375, 'learning_rate': 1.676923076923077e-05, 'epoch': 2.128, 'step': 2660}\n",
      "{'loss': 0.06884765625, 'learning_rate': 1.6615384615384615e-05, 'epoch': 2.136, 'step': 2670}\n",
      "{'loss': 0.0765380859375, 'learning_rate': 1.646153846153846e-05, 'epoch': 2.144, 'step': 2680}\n",
      "{'loss': 0.0205810546875, 'learning_rate': 1.630769230769231e-05, 'epoch': 2.152, 'step': 2690}\n",
      "{'loss': 0.11204833984375, 'learning_rate': 1.6153846153846154e-05, 'epoch': 2.16, 'step': 2700}\n",
      "{'loss': 0.073779296875, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.168, 'step': 2710}\n",
      "{'loss': 0.037969970703125, 'learning_rate': 1.5846153846153848e-05, 'epoch': 2.176, 'step': 2720}\n",
      "{'loss': 0.138140869140625, 'learning_rate': 1.5692307692307693e-05, 'epoch': 2.184, 'step': 2730}\n",
      "{'loss': 0.081591796875, 'learning_rate': 1.553846153846154e-05, 'epoch': 2.192, 'step': 2740}\n",
      "{'loss': 0.128985595703125, 'learning_rate': 1.5384615384615387e-05, 'epoch': 2.2, 'step': 2750}\n",
      "{'loss': 0.027685546875, 'learning_rate': 1.5230769230769232e-05, 'epoch': 2.208, 'step': 2760}\n",
      "{'loss': 0.062554931640625, 'learning_rate': 1.5076923076923078e-05, 'epoch': 2.216, 'step': 2770}\n",
      "{'loss': 0.007501220703125, 'learning_rate': 1.4923076923076923e-05, 'epoch': 2.224, 'step': 2780}\n",
      "{'loss': 0.044110107421875, 'learning_rate': 1.4769230769230772e-05, 'epoch': 2.232, 'step': 2790}\n",
      "{'loss': 0.13934326171875, 'learning_rate': 1.4615384615384617e-05, 'epoch': 2.24, 'step': 2800}\n",
      "{'loss': 0.070684814453125, 'learning_rate': 1.4461538461538462e-05, 'epoch': 2.248, 'step': 2810}\n",
      "{'loss': 0.05020751953125, 'learning_rate': 1.4307692307692308e-05, 'epoch': 2.2560000000000002, 'step': 2820}\n",
      "{'loss': 0.15704345703125, 'learning_rate': 1.4153846153846153e-05, 'epoch': 2.2640000000000002, 'step': 2830}\n",
      "{'loss': 0.07386474609375, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.2720000000000002, 'step': 2840}\n",
      "{'loss': 0.08509521484375, 'learning_rate': 1.3846153846153847e-05, 'epoch': 2.2800000000000002, 'step': 2850}\n",
      "{'loss': 0.064093017578125, 'learning_rate': 1.3692307692307694e-05, 'epoch': 2.288, 'step': 2860}\n",
      "{'loss': 0.00357666015625, 'learning_rate': 1.3538461538461539e-05, 'epoch': 2.296, 'step': 2870}\n",
      "{'loss': 0.06270751953125, 'learning_rate': 1.3384615384615384e-05, 'epoch': 2.304, 'step': 2880}\n",
      "{'loss': 0.046636962890625, 'learning_rate': 1.3230769230769233e-05, 'epoch': 2.312, 'step': 2890}\n",
      "{'loss': 0.012188720703125, 'learning_rate': 1.3076923076923078e-05, 'epoch': 2.32, 'step': 2900}\n",
      "{'loss': 0.06234130859375, 'learning_rate': 1.2923076923076924e-05, 'epoch': 2.328, 'step': 2910}\n",
      "{'loss': 0.069781494140625, 'learning_rate': 1.2769230769230769e-05, 'epoch': 2.336, 'step': 2920}\n",
      "{'loss': 0.048773193359375, 'learning_rate': 1.2615384615384616e-05, 'epoch': 2.344, 'step': 2930}\n",
      "{'loss': 0.07464599609375, 'learning_rate': 1.2461538461538463e-05, 'epoch': 2.352, 'step': 2940}\n",
      "{'loss': 0.084881591796875, 'learning_rate': 1.230769230769231e-05, 'epoch': 2.36, 'step': 2950}\n",
      "{'loss': 0.049261474609375, 'learning_rate': 1.2153846153846155e-05, 'epoch': 2.368, 'step': 2960}\n",
      "{'loss': 0.122149658203125, 'learning_rate': 1.2e-05, 'epoch': 2.376, 'step': 2970}\n",
      "{'loss': 0.053216552734375, 'learning_rate': 1.1846153846153847e-05, 'epoch': 2.384, 'step': 2980}\n",
      "{'loss': 0.048858642578125, 'learning_rate': 1.1692307692307693e-05, 'epoch': 2.392, 'step': 2990}\n",
      "{'loss': 0.098126220703125, 'learning_rate': 1.153846153846154e-05, 'epoch': 2.4, 'step': 3000}\n",
      "{'loss': 0.116619873046875, 'learning_rate': 1.1384615384615385e-05, 'epoch': 2.408, 'step': 3010}\n",
      "{'loss': 0.085003662109375, 'learning_rate': 1.123076923076923e-05, 'epoch': 2.416, 'step': 3020}\n",
      "{'loss': 0.081365966796875, 'learning_rate': 1.1076923076923077e-05, 'epoch': 2.424, 'step': 3030}\n",
      "{'loss': 0.054351806640625, 'learning_rate': 1.0923076923076924e-05, 'epoch': 2.432, 'step': 3040}\n",
      "{'loss': 0.063336181640625, 'learning_rate': 1.0769230769230771e-05, 'epoch': 2.44, 'step': 3050}\n",
      "{'loss': 0.050555419921875, 'learning_rate': 1.0615384615384616e-05, 'epoch': 2.448, 'step': 3060}\n",
      "{'loss': 0.071795654296875, 'learning_rate': 1.0461538461538462e-05, 'epoch': 2.456, 'step': 3070}\n",
      "{'loss': 0.033990478515625, 'learning_rate': 1.0307692307692309e-05, 'epoch': 2.464, 'step': 3080}\n",
      "{'loss': 0.0449462890625, 'learning_rate': 1.0153846153846154e-05, 'epoch': 2.472, 'step': 3090}\n",
      "{'loss': 0.062530517578125, 'learning_rate': 1e-05, 'epoch': 2.48, 'step': 3100}\n",
      "{'loss': 0.04708251953125, 'learning_rate': 9.846153846153846e-06, 'epoch': 2.488, 'step': 3110}\n",
      "{'loss': 0.030242919921875, 'learning_rate': 9.692307692307691e-06, 'epoch': 2.496, 'step': 3120}\n",
      "{'loss': 0.028472900390625, 'learning_rate': 9.538461538461538e-06, 'epoch': 2.504, 'step': 3130}\n",
      "{'loss': 0.04278564453125, 'learning_rate': 9.384615384615385e-06, 'epoch': 2.512, 'step': 3140}\n",
      "{'loss': 0.077655029296875, 'learning_rate': 9.230769230769232e-06, 'epoch': 2.52, 'step': 3150}\n",
      "{'loss': 0.141265869140625, 'learning_rate': 9.076923076923078e-06, 'epoch': 2.528, 'step': 3160}\n",
      "{'loss': 0.129376220703125, 'learning_rate': 8.923076923076923e-06, 'epoch': 2.536, 'step': 3170}\n",
      "{'loss': 0.013787841796875, 'learning_rate': 8.76923076923077e-06, 'epoch': 2.544, 'step': 3180}\n",
      "{'loss': 0.11534423828125, 'learning_rate': 8.615384615384615e-06, 'epoch': 2.552, 'step': 3190}\n",
      "{'loss': 0.211419677734375, 'learning_rate': 8.461538461538462e-06, 'epoch': 2.56, 'step': 3200}\n",
      "{'loss': 0.075103759765625, 'learning_rate': 8.307692307692307e-06, 'epoch': 2.568, 'step': 3210}\n",
      "{'loss': 0.0919921875, 'learning_rate': 8.153846153846154e-06, 'epoch': 2.576, 'step': 3220}\n",
      "{'loss': 0.135394287109375, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.584, 'step': 3230}\n",
      "{'loss': 0.09427490234375, 'learning_rate': 7.846153846153847e-06, 'epoch': 2.592, 'step': 3240}\n",
      "{'loss': 0.0267578125, 'learning_rate': 7.692307692307694e-06, 'epoch': 2.6, 'step': 3250}\n",
      "{'loss': 0.034503173828125, 'learning_rate': 7.538461538461539e-06, 'epoch': 2.608, 'step': 3260}\n",
      "{'loss': 0.12374267578125, 'learning_rate': 7.384615384615386e-06, 'epoch': 2.616, 'step': 3270}\n",
      "{'loss': 0.12071533203125, 'learning_rate': 7.230769230769231e-06, 'epoch': 2.624, 'step': 3280}\n",
      "{'loss': 0.0325927734375, 'learning_rate': 7.076923076923076e-06, 'epoch': 2.632, 'step': 3290}\n",
      "{'loss': 0.02664794921875, 'learning_rate': 6.923076923076923e-06, 'epoch': 2.64, 'step': 3300}\n",
      "{'loss': 0.08675537109375, 'learning_rate': 6.7692307692307695e-06, 'epoch': 2.648, 'step': 3310}\n",
      "{'loss': 0.056683349609375, 'learning_rate': 6.6153846153846165e-06, 'epoch': 2.656, 'step': 3320}\n",
      "{'loss': 0.07596435546875, 'learning_rate': 6.461538461538462e-06, 'epoch': 2.664, 'step': 3330}\n",
      "{'loss': 0.059063720703125, 'learning_rate': 6.307692307692308e-06, 'epoch': 2.672, 'step': 3340}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.08291015625, 'learning_rate': 6.153846153846155e-06, 'epoch': 2.68, 'step': 3350}\n",
      "{'loss': 0.01361083984375, 'learning_rate': 6e-06, 'epoch': 2.6879999999999997, 'step': 3360}\n",
      "{'loss': 0.0572265625, 'learning_rate': 5.846153846153846e-06, 'epoch': 2.6959999999999997, 'step': 3370}\n",
      "{'loss': 0.094732666015625, 'learning_rate': 5.692307692307692e-06, 'epoch': 2.7039999999999997, 'step': 3380}\n",
      "{'loss': 0.050836181640625, 'learning_rate': 5.5384615384615385e-06, 'epoch': 2.7119999999999997, 'step': 3390}\n",
      "{'loss': 0.129412841796875, 'learning_rate': 5.3846153846153855e-06, 'epoch': 2.7199999999999998, 'step': 3400}\n",
      "{'loss': 0.032586669921875, 'learning_rate': 5.230769230769231e-06, 'epoch': 2.7279999999999998, 'step': 3410}\n",
      "{'loss': 0.074041748046875, 'learning_rate': 5.076923076923077e-06, 'epoch': 2.7359999999999998, 'step': 3420}\n",
      "{'loss': 0.041302490234375, 'learning_rate': 4.923076923076923e-06, 'epoch': 2.7439999999999998, 'step': 3430}\n",
      "{'loss': 0.06114501953125, 'learning_rate': 4.769230769230769e-06, 'epoch': 2.752, 'step': 3440}\n",
      "{'loss': 0.085137939453125, 'learning_rate': 4.615384615384616e-06, 'epoch': 2.76, 'step': 3450}\n",
      "{'loss': 0.018231201171875, 'learning_rate': 4.4615384615384614e-06, 'epoch': 2.768, 'step': 3460}\n",
      "{'loss': 0.0525634765625, 'learning_rate': 4.3076923076923076e-06, 'epoch': 2.776, 'step': 3470}\n",
      "{'loss': 0.110614013671875, 'learning_rate': 4.153846153846154e-06, 'epoch': 2.784, 'step': 3480}\n",
      "{'loss': 0.0760498046875, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.792, 'step': 3490}\n",
      "{'loss': 0.046697998046875, 'learning_rate': 3.846153846153847e-06, 'epoch': 2.8, 'step': 3500}\n",
      "{'loss': 0.139251708984375, 'learning_rate': 3.692307692307693e-06, 'epoch': 2.808, 'step': 3510}\n",
      "{'loss': 0.037896728515625, 'learning_rate': 3.538461538461538e-06, 'epoch': 2.816, 'step': 3520}\n",
      "{'loss': 0.10792236328125, 'learning_rate': 3.3846153846153848e-06, 'epoch': 2.824, 'step': 3530}\n",
      "{'loss': 0.1179443359375, 'learning_rate': 3.230769230769231e-06, 'epoch': 2.832, 'step': 3540}\n",
      "{'loss': 0.0721435546875, 'learning_rate': 3.0769230769230774e-06, 'epoch': 2.84, 'step': 3550}\n",
      "{'loss': 0.053131103515625, 'learning_rate': 2.923076923076923e-06, 'epoch': 2.848, 'step': 3560}\n",
      "{'loss': 0.00712890625, 'learning_rate': 2.7692307692307693e-06, 'epoch': 2.856, 'step': 3570}\n",
      "{'loss': 0.070843505859375, 'learning_rate': 2.6153846153846154e-06, 'epoch': 2.864, 'step': 3580}\n",
      "{'loss': 0.005401611328125, 'learning_rate': 2.4615384615384615e-06, 'epoch': 2.872, 'step': 3590}\n",
      "{'loss': 0.056365966796875, 'learning_rate': 2.307692307692308e-06, 'epoch': 2.88, 'step': 3600}\n",
      "{'loss': 0.077569580078125, 'learning_rate': 2.1538461538461538e-06, 'epoch': 2.888, 'step': 3610}\n",
      "{'loss': 0.1197998046875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.896, 'step': 3620}\n",
      "{'loss': 0.058233642578125, 'learning_rate': 1.8461538461538465e-06, 'epoch': 2.904, 'step': 3630}\n",
      "{'loss': 0.002471923828125, 'learning_rate': 1.6923076923076924e-06, 'epoch': 2.912, 'step': 3640}\n",
      "{'loss': 0.10172119140625, 'learning_rate': 1.5384615384615387e-06, 'epoch': 2.92, 'step': 3650}\n",
      "{'loss': 0.122271728515625, 'learning_rate': 1.3846153846153846e-06, 'epoch': 2.928, 'step': 3660}\n",
      "{'loss': 0.052679443359375, 'learning_rate': 1.2307692307692308e-06, 'epoch': 2.936, 'step': 3670}\n",
      "{'loss': 0.06068115234375, 'learning_rate': 1.0769230769230769e-06, 'epoch': 2.944, 'step': 3680}\n",
      "{'loss': 0.064532470703125, 'learning_rate': 9.230769230769232e-07, 'epoch': 2.952, 'step': 3690}\n",
      "{'loss': 0.14150390625, 'learning_rate': 7.692307692307694e-07, 'epoch': 2.96, 'step': 3700}\n",
      "{'loss': 0.054888916015625, 'learning_rate': 6.153846153846154e-07, 'epoch': 2.968, 'step': 3710}\n",
      "{'loss': 0.040631103515625, 'learning_rate': 4.615384615384616e-07, 'epoch': 2.976, 'step': 3720}\n",
      "{'loss': 0.09564208984375, 'learning_rate': 3.076923076923077e-07, 'epoch': 2.984, 'step': 3730}\n",
      "{'loss': 0.02158203125, 'learning_rate': 1.5384615384615385e-07, 'epoch': 2.992, 'step': 3740}\n",
      "{'loss': 0.10892333984375, 'learning_rate': 0.0, 'epoch': 3.0, 'step': 3750}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.183282177734375)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert model\\\\vocab.txt',\n",
       " 'bert model\\\\special_tokens_map.json',\n",
       " 'bert model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"bert model\")\n",
    "tokenizer.save_pretrained(\"bert model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert model\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"bert model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            #if next(model.parameters()).is_cuda:\n",
    "            #    data = [t.to(device) for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            #tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            #outputs = model(input_ids=tokens_tensors, \n",
    "            #                token_type_ids=segments_tensors, \n",
    "            #                attention_mask=masks_tensors)\n",
    "            optim.zero_grad()\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            #labels = data['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=16)\n",
    "predictions = get_predictions(model, testloader)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-2e1b80241150>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencodedd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencodedd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             raise KeyError(\n\u001b[1;32m--> 209\u001b[1;33m                 \u001b[1;34m\"Indexing with integers (to access backend Encoding for a given batch index) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;34m\"is not available when using Python based tokenizers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"
     ]
    }
   ],
   "source": [
    "text = 'this is good.'\n",
    "encoded = tokenizer(text, truncation=True, padding=True)\n",
    "encodedd = DataLoader(encoded, batch_size=1)\n",
    "for batch in encodedd:\n",
    "    batch[index_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "#text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "text = 'not so bad.'\n",
    "#text = 'I viewed the movie together with a homophobic friend, my wife and her female friend. So I had views from all kinds of directions. Mainly, the film made me laugh, the sexual tension was not really there and the only noticeable actors were Tudor Chirila and Maria Popistasu. Yes, I do think she played her role well, even if the script was not appropriate. There were good Romanian actors around, they just didn\\'t have complex roles. I applaud Puya\\'s entering the movie business. I don\\'t know why, but I think he\\'s a good guy, I just hope he\\'ll be a good actor.<br /><br />The wife loved the movie, though, and I think there might have been chords being played and to which I had no ear for. If the film tried to present uncommon sexual behaviors and their consequences in todays Romania, then it failed miserably. There were no consequences. Just imagine that the girls are actually a boy and a girl, and the same story becomes just a boring, uninteresting plot.<br /><br />I have no idea why it got all those BAFTA awards. In my book, it should have gotten the \"Better luck next time\" award.'\n",
    "#text = 'no good'\n",
    "#encoded = tokenizer(text, truncation=True, padding=True)\n",
    "#encodedd = DataLoader(encoded)\n",
    "encoded = tokenizer.encode_plus(text, return_tensors='pt').to(device)\n",
    "seq_relationship_logits = model(**encoded)[0]\n",
    "probs = softmax(seq_relationship_logits, dim=1)\n",
    "_, preds1 = torch.max(probs.data, dim=1)\n",
    "#_, preds2 = torch.max(probs, dim=1)\n",
    "preds1.tolist()\n",
    "#predicted_tokens = tokenizer.convert_ids_to_tokens(preds1[0])\n",
    "#predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I viewed the movie together with a homophobic friend, my wife and her female friend. So I had views from all kinds of directions. Mainly, the film made me laugh, the sexual tension was not really there and the only noticeable actors were Tudor Chirila and Maria Popistasu. Yes, I do think she played her role well, even if the script was not appropriate. There were good Romanian actors around, they just didn\\'t have complex roles. I applaud Puya\\'s entering the movie business. I don\\'t know why, but I think he\\'s a good guy, I just hope he\\'ll be a good actor.<br /><br />The wife loved the movie, though, and I think there might have been chords being played and to which I had no ear for. If the film tried to present uncommon sexual behaviors and their consequences in todays Romania, then it failed miserably. There were no consequences. Just imagine that the girls are actually a boy and a girl, and the same story becomes just a boring, uninteresting plot.<br /><br />I have no idea why it got all those BAFTA awards. In my book, it should have gotten the \"Better luck next time\" award. (bafta=good luck in Romanian).',\n",
       " 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0], train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0865, -0.7266,  0.2697,  ...,  0.7230, -0.1993, -0.2673],\n",
       "          [ 0.0124, -0.6388,  0.2815,  ...,  0.6794, -0.2216, -0.1828],\n",
       "          [ 0.0114, -0.6859,  0.3307,  ...,  0.6306, -0.2857, -0.1467],\n",
       "          [-0.0340, -0.5850,  0.5152,  ...,  0.6593, -0.4234, -0.4688],\n",
       "          [-0.0872, -0.6707,  0.1509,  ...,  0.6818, -0.3874, -0.4071],\n",
       "          [-0.0176, -0.6539,  0.2366,  ...,  0.7779, -0.5380, -0.3840]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encodedd = tokenizer(text, truncation=True, padding=True)\n",
    "#encodedd, encoded\n",
    "model(**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cceb74320e4b1a9a575aea2e355aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=1.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-a7cfdb2b5040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, eval_dataset)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[0meval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Evaluation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[0;32m   1235\u001b[0m         \u001b[0mdisable_tqdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_local_process_zero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m         \u001b[0msamples_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1237\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1238\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2.1.0\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             raise KeyError(\n\u001b[1;32m--> 209\u001b[1;33m                 \u001b[1;34m\"Indexing with integers (to access backend Encoding for a given batch index) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;34m\"is not available when using Python based tokenizers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.1.0",
   "language": "python",
   "name": "tensorflow2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
